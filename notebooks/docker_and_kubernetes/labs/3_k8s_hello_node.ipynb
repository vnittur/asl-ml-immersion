{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello Node Kubernetes\n",
    "\n",
    "**Learning Objectives**\n",
    " * Create a Node.js server\n",
    " * Create a Docker container image\n",
    " * Create a container cluster and a Kubernetes pod\n",
    " * Scale up your services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The goal of this hands-on lab is for you to turn code that you have developed into a replicated application running on Kubernetes, which is running on Kubernetes Engine. For this lab the code will be a simple Hello World node.js app.\n",
    "\n",
    "Here's a diagram of the various parts in play in this lab, to help you understand how the pieces fit together with one another. Use this as a reference as you progress through the lab; it should all make sense by the time you get to the end (but feel free to ignore this for now).\n",
    "\n",
    "<img src='../assets/k8s_hellonode_overview.png' width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Node.js server\n",
    "\n",
    "The file `./src/server.js` contains a simple Node.js server. Use `cat` to examine the contents of that file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var http = require('http');\n",
      "var handleRequest = function(request, response) {\n",
      "  response.writeHead(200);\n",
      "  response.end(\"Hello World!\\n\");\n",
      "}\n",
      "var www = http.createServer(handleRequest);\n",
      "www.listen(8000);\n"
     ]
    }
   ],
   "source": [
    "!cat ./src/server.js"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the server by running `node server.js` in the cell below. Open a terminal and type\n",
    "```bash\n",
    "curl http://localhost:8000\n",
    "```\n",
    "to see what the server outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!node ./src/server.js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curl: (7) Failed to connect to localhost port 8000: Connection refused\n"
     ]
    }
   ],
   "source": [
    "!curl http://localhost:8000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the output `\"Hello World!\"`. Once you've verfied this, interupt the above running cell by hitting the stop button."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and build a Docker image\n",
    "\n",
    "Now we will create a docker image called `hello_node.docker` that will do the following:\n",
    "\n",
    " 1. Start from the node image found on the Docker hub by inhereting from `node:6.9.2`\n",
    " 2. Expose port 8000\n",
    " 3. Copy the `./src/server.js` file to the image\n",
    " 4. Start the node server as we previously did manually using `CMD`\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Edit the file called called `hello_node.docker` in the `dockerfiles` folder to complete all the TODOs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, build the image in your project using `docker build`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PROJECT_ID = \"qwiklabs-gcp-01-9a9d18213c32\"  # REPLACE WITH YOUR PROJECT NAME\n",
    "os.environ[\"PROJECT_ID\"] = PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Use `docker build` to build the image from dockerfile you created above. Tag the image as `gcr.io/[project-id]/hello-node:v1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  134.7kB\n",
      "Step 1/5 : FROM node:stretch-slim\n",
      " ---> 52de4a21b501\n",
      "Step 2/5 : WORKDIR /app\n",
      " ---> Using cache\n",
      " ---> 20b337a04125\n",
      "Step 3/5 : COPY ./src /app\n",
      " ---> Using cache\n",
      " ---> 28755aaec5ee\n",
      "Step 4/5 : EXPOSE 8000\n",
      " ---> Using cache\n",
      " ---> 19ac46956ef1\n",
      "Step 5/5 : CMD [ \"node\", \"server.js\" ]\n",
      " ---> Using cache\n",
      " ---> e9195835a3c5\n",
      "Successfully built e9195835a3c5\n",
      "Successfully tagged test:test\n"
     ]
    }
   ],
   "source": [
    "!docker build -t test:test . -f dockerfiles/hello_node.docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker tag test:test gcr.io/qwiklabs-gcp-01-9a9d18213c32/hello-node:v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It'll take some time to download and extract everything, but you can see the progress bars as the image builds. Once complete, test the image locally by running a Docker container as a daemon on port 8000 from your newly-created container image.\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Run the container using `docker run` on the port 8000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY                                       TAG            IMAGE ID       CREATED         SIZE\n",
      "test                                             test           e9195835a3c5   3 minutes ago   216MB\n",
      "gcr.io/qwiklabs-gcp-01-9a9d18213c32/hello-node   v1             e9195835a3c5   3 minutes ago   216MB\n",
      "gcr.io/qwiklabs-gcp-01-9a9d18213c32/node-app     0.2            853f4b2bbbff   22 hours ago    216MB\n",
      "<none>                                           <none>         232484aa70da   22 hours ago    216MB\n",
      "<none>                                           <none>         b0453864e62e   22 hours ago    216MB\n",
      "node                                             stretch-slim   52de4a21b501   5 days ago      216MB\n",
      "node                                             latest         ba17ecfd099c   5 days ago      991MB\n",
      "gcr.io/inverting-proxy/agent                     <none>         fe507176d0e6   13 months ago   1.73GB\n"
     ]
    }
   ],
   "source": [
    "!docker images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE                                               COMMAND                  CREATED          STATUS          PORTS                            NAMES\n",
      "cc1003c9e2b4   gcr.io/qwiklabs-gcp-01-9a9d18213c32/hello-node:v1   \"docker-entrypoint.s…\"   21 seconds ago   Up 20 seconds   8000/tcp                         fervent_nobel\n",
      "1abfbfcae857   gcr.io/qwiklabs-gcp-01-9a9d18213c32/node-app:0.2    \"docker-entrypoint.s…\"   21 hours ago     Up 21 hours     4000/tcp, 0.0.0.0:4000->80/tcp   pensive_goldwasser\n",
      "bd408fa7ce9b   853f4b2bbbff                                        \"docker-entrypoint.s…\"   22 hours ago     Up 22 hours     0.0.0.0:80->80/tcp, 4000/tcp     trusting_almeida\n",
      "ddc3d7eb3a49   gcr.io/inverting-proxy/agent                        \"/bin/sh -c '/opt/bi…\"   22 hours ago     Up 22 hours                                      proxy-agent\n"
     ]
    }
   ],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cc1003c9e2b44110738c8fa052ff428191de41caf37ea0cd86f0938e9d254dc3\n"
     ]
    }
   ],
   "source": [
    "!docker run -d gcr.io/qwiklabs-gcp-01-9a9d18213c32/hello-node:v1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your output should look something like this:\n",
    "```bash\n",
    "b16e5ccb74dc39b0b43a5b20df1c22ff8b41f64a43aef15e12cc9ac3b3f47cfd\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, since you used the `--d` flag, the container process is running in the background. You can verify it's running using `curl` as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curl: (7) Failed to connect to localhost port 8000: Connection refused\n"
     ]
    }
   ],
   "source": [
    "!curl http://localhost:8000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, stop running the container. Get the container id using `docker ps` and then terminate using `docker stop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cc1003c9e2b4\n"
     ]
    }
   ],
   "source": [
    "# your container id will be different\n",
    "!docker stop cc1003c9e2b4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the image is working as intended, push it to the Google Container Registry, a private repository for your Docker images, accessible from your Google Cloud projects. First, configure docker uisng your local config file. The initial push may take a few minutes to complete. You'll see the progress bars as it builds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m Your config file at [/home/jupyter/.docker/config.json] contains these credential helper entries:\n",
      "\n",
      "{\n",
      "  \"credHelpers\": {\n",
      "    \"gcr.io\": \"gcloud\",\n",
      "    \"us.gcr.io\": \"gcloud\",\n",
      "    \"eu.gcr.io\": \"gcloud\",\n",
      "    \"asia.gcr.io\": \"gcloud\",\n",
      "    \"staging-k8s.gcr.io\": \"gcloud\",\n",
      "    \"marketplace.gcr.io\": \"gcloud\"\n",
      "  }\n",
      "}\n",
      "Adding credentials for all GCR repositories.\n",
      "\u001b[1;33mWARNING:\u001b[0m A long list of credential helpers may cause delays running 'docker build'. We recommend passing the registry name to configure only the registry you are using.\n",
      "gcloud credential helpers already registered correctly.\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth configure-docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Push the `hello-node:v1` image to your Cloud gcr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [gcr.io/qwiklabs-gcp-01-9a9d18213c32/hello-node]\n",
      "\n",
      "\u001b[1B4f2199b5: Preparing \n",
      "\u001b[1B2ce66471: Preparing \n",
      "\u001b[1B25f798a2: Preparing \n",
      "\u001b[1Bb3c2e315: Preparing \n",
      "\u001b[1B6f306d7d: Preparing \n",
      "\u001b[1Bd82b89f1: Preparing \n",
      "\u001b[1Bdd17aa8c: Layer already exists \u001b[5A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2Kv1: digest: sha256:bf942c365a4de57060ed424efb3625fdab58543db883894d9622572b5ee20627 size: 1781\n"
     ]
    }
   ],
   "source": [
    "!docker push gcr.io/qwiklabs-gcp-01-9a9d18213c32/hello-node:v1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The container image will be listed in your Console. Select `Navigation` > `Container Registry`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a cluster on GKE\n",
    "\n",
    "Now you're ready to create your Kubernetes Engine cluster. A cluster consists of a Kubernetes master API server hosted by Google and a set of worker nodes. The worker nodes are Compute Engine virtual machines.\n",
    "\n",
    "Create a cluster with two n1-standard-1 nodes (this will take a few minutes to complete). You can safely ignore warnings that come up when the cluster builds.\n",
    "\n",
    "**Note**: You can also create this cluster through the Console by opening the Navigation menu and selecting `Kubernetes Engine` > `Kubernetes clusters` > `Create cluster`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** \n",
    "\n",
    "Create a GKE cluster in your project using `gcloud container clusters create`. Your cluster should\n",
    " 1. be named `hello-world`\n",
    " 2. have two nodes\n",
    " 3. consist of `n1-standard-1` machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "CLUSTER_NAME = \"asl-cluster\"\n",
    "ZONE = \"us-central1-a\"\n",
    "\n",
    "os.environ[\"CLUSTER_NAME\"] = CLUSTER_NAME\n",
    "os.environ[\"ZONE\"] = ZONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default change: VPC-native is the default mode during cluster creation for versions greater than 1.21.0-gke.1500. To create advanced routes based clusters, please pass the `--no-enable-ip-alias` flag\n",
      "Note: Your Pod address range (`--cluster-ipv4-cidr`) can accommodate at most 1008 node(s).\n",
      "Creating cluster asl-cluster in us-central1-a... Cluster is being configured...\n",
      "⠛                                                                              \n",
      "Creating cluster asl-cluster in us-central1-a... Cluster is being health-checke\n",
      "d (master is healthy)...done.                                                  \n",
      "Created [https://container.googleapis.com/v1/projects/qwiklabs-gcp-01-9a9d18213c32/zones/us-central1-a/clusters/asl-cluster].\n",
      "To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-central1-a/asl-cluster?project=qwiklabs-gcp-01-9a9d18213c32\n",
      "kubeconfig entry generated for asl-cluster.\n",
      "NAME         LOCATION       MASTER_VERSION   MASTER_IP     MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS\n",
      "asl-cluster  us-central1-a  1.21.9-gke.1002  34.136.21.79  e2-medium     1.21.9-gke.1002  3          RUNNING\n"
     ]
    }
   ],
   "source": [
    "!gcloud container clusters create $CLUSTER_NAME --zone us-central1-a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a pod\n",
    "\n",
    "A Kubernetes pod is a group of containers tied together for administration and networking purposes. It can contain single or multiple containers. Here you'll use one container built with your `Node.js` image stored in your private container registry. It will serve content on port 8000.\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Create a pod with the `kubectl create` command. You should \n",
    " 1. name your deployment `hello-node`\n",
    " 2. be based on the image you created above called `gcr.io/[project-id]/hello-node:v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching cluster endpoint and auth data.\n",
      "kubeconfig entry generated for asl-cluster.\n"
     ]
    }
   ],
   "source": [
    "!gcloud container clusters get-credentials $CLUSTER_NAME --zone $ZONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/hello-node created\n"
     ]
    }
   ],
   "source": [
    "!kubectl create deployment hello-node --image gcr.io/qwiklabs-gcp-01-9a9d18213c32/hello-node:v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service/hello-node1 exposed\n"
     ]
    }
   ],
   "source": [
    "!kubectl expose deployment hello-node --type=LoadBalancer --name=hello-node1 --port=8000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, you've created a deployment object. Deployments are the recommended way to create and scale pods. Here, a new deployment manages a single pod replica running the `hello-node:v1` image.\n",
    "\n",
    "View the deployment using `kubectl get`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME           READY   UP-TO-DATE   AVAILABLE   AGE\n",
      "hello-node     1/1     1            1           4m39s\n",
      "hello-server   1/1     1            1           5m18s\n",
      "deployment.apps \"hello-node\" deleted\n"
     ]
    }
   ],
   "source": [
    "!kubectl get deployments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, view the pods created by the deployment by also using `kubectl get`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME          TYPE           CLUSTER-IP    EXTERNAL-IP       PORT(S)          AGE\n",
      "hello-node    LoadBalancer   10.88.6.196   34.72.12.126      8001:31460/TCP   5m16s\n",
      "hello-node1   LoadBalancer   10.88.3.124   <pending>         8000:31464/TCP   30s\n",
      "kubernetes    ClusterIP      10.88.0.1     <none>            443/TCP          8m9s\n",
      "my-service    LoadBalancer   10.88.13.28   104.197.134.202   8000:32251/TCP   5m33s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some other good kubectl commands you should know. They won't change the state of the cluster. Others can be found [here](https://kubernetes.io/docs/reference/kubectl/overview/).\n",
    " * `kubectl cluster-info`\n",
    " * `kubectl config view`\n",
    " * `kubectl get events`\n",
    " * `kubectl logs <pod-name>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allow external traffic\n",
    "\n",
    "By default, the pod is only accessible by its internal IP within the cluster. In order to make the hello-node container accessible from outside the Kubernetes virtual network, you have to expose the pod as a Kubernetes service.\n",
    "\n",
    "You can expose the pod to the public internet with the `kubectl expose` command. The `--type=\"LoadBalancer\"` flag is required for the creation of an externally accessible IP. This flag specifies that are using the load-balancer provided by the underlying infrastructure (in this case the Compute Engine load balancer). Note that you expose the deployment, and not the pod, directly. This will cause the resulting service to load balance traffic across all pods managed by the deployment (in this case only 1 pod, but you will add more replicas later).\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Expose the pod using `kubectl expose` and using the default load-balancer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "TODO: Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kubernetes master creates the load balancer and related Compute Engine forwarding rules, target pools, and firewall rules to make the service fully accessible from outside of Google Cloud.\n",
    "\n",
    "To find the publicly-accessible IP address of the service, request kubectl to list all the cluster services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 IP addresses listed for your `hello-node` service, both serving port 8000. The `CLUSTER-IP` is the internal IP that is only visible inside your cloud virtual network; the `EXTERNAL-IP` is the external load-balanced IP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now be able to reach the service by calling `curl http://<EXTERNAL_IP>:8000`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curl: (7) Failed to connect to 10.88.3.124 port 8000: Connection timed out\n"
     ]
    }
   ],
   "source": [
    "!curl http://10.88.3.124:8000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point you've gained several features from moving to containers and Kubernetes - you do not need to specify on which host to run your workload and you also benefit from service monitoring and restart. Now see what else can be gained from your new Kubernetes infrastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale up your service\n",
    "One of the powerful features offered by Kubernetes is how easy it is to scale your application. Suppose you suddenly need more capacity. You can tell the replication controller to manage a new number of replicas for your pod: \n",
    "```bash\n",
    "kubectl scale deployment hello-node --replicas=4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale your `hello-node` application to have 6 replicas. Then use `kubectl get` to request a description of the updated deployment and list all the pods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Use the `kubectl scale deployment` command to scale up the `hello-node` service to six machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "TODO: Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A declarative approach is being used here. Rather than starting or stopping new instances, you declare how many instances should be running at all times. Kubernetes reconciliation loops makes sure that reality matches what you requested and takes action if needed.\n",
    "\n",
    "Here's a diagram summarizing the state of your Kubernetes cluster:\n",
    "\n",
    "<img src='../assets/k8s_cluster.png' width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roll out an upgrade to your service\n",
    "At some point the application that you've deployed to production will require bug fixes or additional features. Kubernetes helps you deploy a new version to production without impacting your users.\n",
    "\n",
    "First, modify the application by opening `server.js` so that the response is \n",
    "```bash\n",
    "response.end(\"Hello Kubernetes World!\");\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can build and publish a new container image to the registry with an incremented tag (`v2` in this case).\n",
    "\n",
    "**Note**: Building and pushing this updated image should be quicker since caching is being taken advantage of."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Build and push the updated image using the `hello_node.docker` file. Tag the updated image as `gcr.io/[project-id]/hello-node:v2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "TODO: Your code goes here\n",
    "TODO: Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kubernetes will smoothly update your replication controller to the new version of the application. In order to change the image label for your running container, you will edit the existing `hello-node` deployment and change the image from `gcr.io/PROJECT_ID/hello-node:v1` to `gcr.io/PROJECT_ID/hello-node:v2`.\n",
    "\n",
    "To do this, use the `kubectl edit` command. It opens a text editor displaying the full deployment yaml configuration. It isn't necessary to understand the full yaml config right now, just understand that by updating the `spec.template.spec.containers.image` field in the config you are telling the deployment to update the pods with the new image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open a terminal and run the following command:\n",
    "\n",
    "```bash \n",
    "kubectl edit deployment hello-node\n",
    "```\n",
    "\n",
    "Look for `Spec` > `containers` > `image` and change the version number to `v2`. This is the output you should see:\n",
    "\n",
    "```bash\n",
    "deployment.extensions/hello-node edited\n",
    "```\n",
    "\n",
    "New pods will be created with the new image and the old pods will be deleted. Run `kubectl get deployments` to confirm. \n",
    "\n",
    "**Note**: You may need to rerun the above command as it provisions machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get deployments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is happening, the users of your services shouldn't see any interruption. After a little while they'll start accessing the new version of your application. You can find more details on rolling updates in this documentation.\n",
    "\n",
    "Hopefully with these deployment, scaling, and updated features, once you've set up your Kubernetes Engine cluster, you'll agree that Kubernetes will help you focus on the application rather than the infrastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Delete the cluster using `gcloud` to free up those resources. Use the `--quiet` flag if you are executing this in a notebook. Deleting the cluster can take a few minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud container clusters --quiet delete hello-world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2020 Google LLC Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at https://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
