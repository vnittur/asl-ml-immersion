{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Continuous training with TFX and Vertex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "1. Containerize your TFX code into a pipeline package using Cloud Build.\n",
    "1. Use the TFX CLI to compile a TFX pipeline.\n",
    "1. Deploy a TFX pipeline version to run on Vertex Pipelines using the Vertex Python SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform as vertex_ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate lab package version installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.8.0\n",
      "TFX version: 1.7.0\n",
      "KFP version: 1.8.11\n",
      "aiplatform: 1.11.0\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import tensorflow as tf; print(f'TF version: {tf.__version__}')\"\n",
    "!python -c \"import tfx; print(f'TFX version: {tfx.__version__}')\"\n",
    "!python -c \"import kfp; print(f'KFP version: {kfp.__version__}')\"\n",
    "print(f\"aiplatform: {vertex_ai.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: this lab was built and tested with the following package versions:\n",
    "\n",
    "`TF version: 2.6.2`\n",
    "\n",
    "`TFX version: 1.4.0` \n",
    "\n",
    "`KFP version: 1.8.1`\n",
    "\n",
    "`aiplatform: 1.7.1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review: example TFX pipeline design pattern for Vertex\n",
    "The pipeline source code can be found in the `pipeline_vertex` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'pipeline_vertex'\n",
      "/home/jupyter/asl-ml-immersion/notebooks/tfx_pipelines/pipeline/labs/pipeline_vertex\n"
     ]
    }
   ],
   "source": [
    "%cd pipeline_vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 80\n",
      "drwxr-xr-x 5 jupyter jupyter  4096 Apr  1 16:49 .\n",
      "drwxr-xr-x 5 jupyter jupyter  4096 Apr  1 16:41 ..\n",
      "drwxr-xr-x 2 jupyter jupyter  4096 Apr  1 16:47 .ipynb_checkpoints\n",
      "-rw-r--r-- 1 jupyter jupyter   131 Mar 28 15:49 Dockerfile\n",
      "drwxr-xr-x 2 jupyter jupyter  4096 Apr  1 16:27 __pycache__\n",
      "-rw-r--r-- 1 jupyter jupyter  2044 Apr  1 16:49 config.py\n",
      "-rw-r--r-- 1 jupyter jupyter  1090 Mar 28 15:49 features.py\n",
      "-rw-r--r-- 1 jupyter jupyter  6482 Mar 28 15:49 model.py\n",
      "-rw-r--r-- 1 jupyter jupyter  5657 Mar 28 15:49 pipeline.py\n",
      "-rw-r--r-- 1 jupyter jupyter  2182 Mar 28 15:49 preprocessing.py\n",
      "-rw-r--r-- 1 jupyter jupyter  1322 Mar 28 15:49 runner.py\n",
      "drwxr-xr-x 2 jupyter jupyter  4096 Mar 28 15:49 schema\n",
      "-rw-r--r-- 1 jupyter jupyter 21972 Apr  1 16:27 tfxcovertype.json\n"
     ]
    }
   ],
   "source": [
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `config.py` module configures the default values for the environment specific settings and the default values for the pipeline runtime parameters. \n",
    "The default values can be overwritten at compile time by providing the updated values in a set of environment variables. You will set custom environment variables later on this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pipeline.py` module contains the TFX DSL defining the workflow implemented by the pipeline.\n",
    "\n",
    "The `preprocessing.py` module implements the data preprocessing logic  the `Transform` component.\n",
    "\n",
    "The `model.py` module implements the TensorFlow model code and training logic for the `Trainer` component.\n",
    "\n",
    "The `runner.py` module configures and executes `KubeflowV2DagRunner`. At compile time, the `KubeflowDagRunner.run()` method converts the TFX DSL into the pipeline package into a JSON format for execution on Vertex.\n",
    "\n",
    "The `features.py` module contains feature definitions common across `preprocessing.py` and `model.py`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: build your pipeline with the TFX CLI\n",
    "\n",
    "You will use TFX CLI to compile and deploy the pipeline. As explained in the previous section, the environment specific settings can be provided through a set of environment variables and embedded into the pipeline package at compile time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure your environment resource settings\n",
    "\n",
    "Update  the below constants  with the settings reflecting your lab environment. \n",
    "\n",
    "- `REGION` - the compute region for AI Platform Training, Vizier, and Prediction.\n",
    "- `ARTIFACT_STORE` - An existing GCS bucket. You can use any bucket, but we will use here the bucket with the same name as the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set your environment resource settings here for GCP_REGION, ARTIFACT_STORE_URI, ENDPOINT, and CUSTOM_SERVICE_ACCOUNT.\n",
    "REGION = \"us-central1\"\n",
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "ARTIFACT_STORE = f\"gs://{PROJECT_ID}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: REGION=us-central1\n",
      "env: ARTIFACT_STORE=gs://qwiklabs-gcp-01-9a9d18213c32\n",
      "env: PROJECT_ID=qwiklabs-gcp-01-9a9d18213c32\n"
     ]
    }
   ],
   "source": [
    "# Set your resource settings as environment variables. These override the default values in pipeline/config.py.\n",
    "%env REGION={REGION}\n",
    "%env ARTIFACT_STORE={ARTIFACT_STORE}\n",
    "%env PROJECT_ID={PROJECT_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-gcp-01-9a9d18213c32/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls | grep ^{ARTIFACT_STORE}/$ || gsutil mb -l {REGION} {ARTIFACT_STORE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Set the compile time settings to first create a pipeline version without hyperparameter tuning\n",
    "\n",
    "Default pipeline runtime environment values are configured in the pipeline folder `config.py`. You will set their values directly below:\n",
    "\n",
    "* `PIPELINE_NAME` - the pipeline's globally unique name.\n",
    "\n",
    "* `DATA_ROOT_URI` - the URI for the raw lab dataset `gs://{PROJECT_ID}/data/tfxcovertype`.\n",
    "\n",
    "* `TFX_IMAGE_URI` - the image name of your pipeline container that will be used to execute each of your tfx components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME = \"tfxcovertype\"\n",
    "DATA_ROOT_URI = f\"gs://{PROJECT_ID}/data/tfxcovertype\"\n",
    "TFX_IMAGE_URI = f\"gcr.io/{PROJECT_ID}/{PIPELINE_NAME}\"\n",
    "PIPELINE_JSON = f\"{PIPELINE_NAME}.json\"\n",
    "\n",
    "TRAIN_STEPS = 10\n",
    "EVAL_STEPS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PIPELINE_NAME=tfxcovertype\n",
      "env: DATA_ROOT_URI=gs://qwiklabs-gcp-01-9a9d18213c32/data/tfxcovertype\n",
      "env: TFX_IMAGE_URI=gcr.io/qwiklabs-gcp-01-9a9d18213c32/tfxcovertype\n",
      "env: PIPELINE_JSON=tfxcovertype.json\n",
      "env: TRAIN_STEPS=10\n",
      "env: EVAL_STEPS=5\n"
     ]
    }
   ],
   "source": [
    "%env PIPELINE_NAME={PIPELINE_NAME}\n",
    "%env DATA_ROOT_URI={DATA_ROOT_URI}\n",
    "%env TFX_IMAGE_URI={TFX_IMAGE_URI}\n",
    "%env PIPELINE_JSON={PIPELINE_JSON}\n",
    "%env TRAIN_STEPS={TRAIN_STEPS}\n",
    "%env EVAL_STEPS={EVAL_STEPS}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us populate the data bucket at `DATA_ROOT_URI`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://../../../data/dataset.csv [Content-Type=text/csv]...\n",
      "/ [1 files][  5.3 MiB/  5.3 MiB]                                                \n",
      "Operation completed over 1 objects/5.3 MiB.                                      \n",
      "gs://qwiklabs-gcp-01-9a9d18213c32/data/tfxcovertype/dataset.csv\n"
     ]
    }
   ],
   "source": [
    "!gsutil cp  ../../../data/* $DATA_ROOT_URI/dataset.csv\n",
    "!gsutil ls $DATA_ROOT_URI/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us build and push the TFX container image described in the `Dockerfile`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 20 file(s) totalling 88.5 KiB before compression.\n",
      "Uploading tarball of [.] to [gs://qwiklabs-gcp-01-9a9d18213c32_cloudbuild/source/1648831847.092317-b1d29685a6e544ccb74429d40bf51f98.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/qwiklabs-gcp-01-9a9d18213c32/locations/global/builds/0930a72f-dd9a-496f-9a36-192540c67ca0].\n",
      "Logs are available at [https://console.cloud.google.com/cloud-build/builds/0930a72f-dd9a-496f-9a36-192540c67ca0?project=785019792420].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"0930a72f-dd9a-496f-9a36-192540c67ca0\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://qwiklabs-gcp-01-9a9d18213c32_cloudbuild/source/1648831847.092317-b1d29685a6e544ccb74429d40bf51f98.tgz#1648831847329340\n",
      "Copying gs://qwiklabs-gcp-01-9a9d18213c32_cloudbuild/source/1648831847.092317-b1d29685a6e544ccb74429d40bf51f98.tgz#1648831847329340...\n",
      "/ [1 files][ 18.6 KiB/ 18.6 KiB]                                                \n",
      "Operation completed over 1 objects/18.6 KiB.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  108.5kB\n",
      "Step 1/4 : FROM gcr.io/tfx-oss-public/tfx:1.4.0\n",
      "1.4.0: Pulling from tfx-oss-public/tfx\n",
      "e4ca327ec0e7: Pulling fs layer\n",
      "0fa9fc055636: Pulling fs layer\n",
      "448bb2d7fba5: Pulling fs layer\n",
      "a084e2627368: Pulling fs layer\n",
      "de932d3a14d8: Pulling fs layer\n",
      "ebe7db8e97e0: Pulling fs layer\n",
      "66fef8aabad3: Pulling fs layer\n",
      "9696f5331161: Pulling fs layer\n",
      "7799e2177407: Pulling fs layer\n",
      "56d35ebee226: Pulling fs layer\n",
      "f23d5847df7e: Pulling fs layer\n",
      "85729b3aa914: Pulling fs layer\n",
      "27594cd25c9b: Pulling fs layer\n",
      "420dbd17143e: Pulling fs layer\n",
      "71797a45a0de: Pulling fs layer\n",
      "b073ad8b8421: Pulling fs layer\n",
      "4b7516634a4b: Pulling fs layer\n",
      "434af55afd20: Pulling fs layer\n",
      "85d42009e725: Pulling fs layer\n",
      "6d895d7b587a: Pulling fs layer\n",
      "9ff76d709282: Pulling fs layer\n",
      "4160ec915caf: Pulling fs layer\n",
      "eb84f1e37919: Pulling fs layer\n",
      "a616daa88ca5: Pulling fs layer\n",
      "99b8f7435830: Pulling fs layer\n",
      "1e2f495eab09: Pulling fs layer\n",
      "d880b09bf9ec: Pulling fs layer\n",
      "403fe241a00b: Pulling fs layer\n",
      "ca533ed5e802: Pulling fs layer\n",
      "9d118b4c5fa6: Pulling fs layer\n",
      "388915f48178: Pulling fs layer\n",
      "ddeefb06ab95: Pulling fs layer\n",
      "62d0755e4559: Pulling fs layer\n",
      "58a229d727c0: Pulling fs layer\n",
      "c4606a99c9de: Pulling fs layer\n",
      "a084e2627368: Waiting\n",
      "de932d3a14d8: Waiting\n",
      "ebe7db8e97e0: Waiting\n",
      "66fef8aabad3: Waiting\n",
      "9696f5331161: Waiting\n",
      "7799e2177407: Waiting\n",
      "56d35ebee226: Waiting\n",
      "f23d5847df7e: Waiting\n",
      "85729b3aa914: Waiting\n",
      "27594cd25c9b: Waiting\n",
      "420dbd17143e: Waiting\n",
      "71797a45a0de: Waiting\n",
      "b073ad8b8421: Waiting\n",
      "4b7516634a4b: Waiting\n",
      "434af55afd20: Waiting\n",
      "85d42009e725: Waiting\n",
      "6d895d7b587a: Waiting\n",
      "9ff76d709282: Waiting\n",
      "4160ec915caf: Waiting\n",
      "eb84f1e37919: Waiting\n",
      "a616daa88ca5: Waiting\n",
      "99b8f7435830: Waiting\n",
      "1e2f495eab09: Waiting\n",
      "d880b09bf9ec: Waiting\n",
      "403fe241a00b: Waiting\n",
      "ca533ed5e802: Waiting\n",
      "9d118b4c5fa6: Waiting\n",
      "388915f48178: Waiting\n",
      "ddeefb06ab95: Waiting\n",
      "62d0755e4559: Waiting\n",
      "58a229d727c0: Waiting\n",
      "c4606a99c9de: Waiting\n",
      "0fa9fc055636: Verifying Checksum\n",
      "0fa9fc055636: Download complete\n",
      "a084e2627368: Verifying Checksum\n",
      "a084e2627368: Download complete\n",
      "e4ca327ec0e7: Verifying Checksum\n",
      "e4ca327ec0e7: Download complete\n",
      "448bb2d7fba5: Verifying Checksum\n",
      "448bb2d7fba5: Download complete\n",
      "de932d3a14d8: Verifying Checksum\n",
      "de932d3a14d8: Download complete\n",
      "66fef8aabad3: Verifying Checksum\n",
      "66fef8aabad3: Download complete\n",
      "7799e2177407: Verifying Checksum\n",
      "7799e2177407: Download complete\n",
      "e4ca327ec0e7: Pull complete\n",
      "0fa9fc055636: Pull complete\n",
      "448bb2d7fba5: Pull complete\n",
      "a084e2627368: Pull complete\n",
      "de932d3a14d8: Pull complete\n",
      "9696f5331161: Verifying Checksum\n",
      "9696f5331161: Download complete\n",
      "f23d5847df7e: Verifying Checksum\n",
      "f23d5847df7e: Download complete\n",
      "56d35ebee226: Verifying Checksum\n",
      "56d35ebee226: Download complete\n",
      "27594cd25c9b: Verifying Checksum\n",
      "27594cd25c9b: Download complete\n",
      "420dbd17143e: Verifying Checksum\n",
      "420dbd17143e: Download complete\n",
      "71797a45a0de: Verifying Checksum\n",
      "71797a45a0de: Download complete\n",
      "ebe7db8e97e0: Verifying Checksum\n",
      "ebe7db8e97e0: Download complete\n",
      "4b7516634a4b: Verifying Checksum\n",
      "4b7516634a4b: Download complete\n",
      "434af55afd20: Verifying Checksum\n",
      "434af55afd20: Download complete\n",
      "85d42009e725: Verifying Checksum\n",
      "85d42009e725: Download complete\n",
      "6d895d7b587a: Verifying Checksum\n",
      "6d895d7b587a: Download complete\n",
      "9ff76d709282: Verifying Checksum\n",
      "9ff76d709282: Download complete\n",
      "4160ec915caf: Verifying Checksum\n",
      "4160ec915caf: Download complete\n",
      "eb84f1e37919: Verifying Checksum\n",
      "eb84f1e37919: Download complete\n",
      "a616daa88ca5: Verifying Checksum\n",
      "a616daa88ca5: Download complete\n",
      "99b8f7435830: Verifying Checksum\n",
      "99b8f7435830: Download complete\n",
      "b073ad8b8421: Verifying Checksum\n",
      "b073ad8b8421: Download complete\n",
      "85729b3aa914: Verifying Checksum\n",
      "85729b3aa914: Download complete\n",
      "1e2f495eab09: Verifying Checksum\n",
      "1e2f495eab09: Download complete\n",
      "403fe241a00b: Verifying Checksum\n",
      "403fe241a00b: Download complete\n",
      "9d118b4c5fa6: Verifying Checksum\n",
      "9d118b4c5fa6: Download complete\n",
      "388915f48178: Verifying Checksum\n",
      "388915f48178: Download complete\n",
      "ddeefb06ab95: Verifying Checksum\n",
      "ddeefb06ab95: Download complete\n",
      "62d0755e4559: Verifying Checksum\n",
      "62d0755e4559: Download complete\n",
      "58a229d727c0: Verifying Checksum\n",
      "58a229d727c0: Download complete\n",
      "ca533ed5e802: Verifying Checksum\n",
      "ca533ed5e802: Download complete\n",
      "d880b09bf9ec: Verifying Checksum\n",
      "d880b09bf9ec: Download complete\n",
      "c4606a99c9de: Verifying Checksum\n",
      "c4606a99c9de: Download complete\n",
      "ebe7db8e97e0: Pull complete\n",
      "66fef8aabad3: Pull complete\n",
      "9696f5331161: Pull complete\n",
      "7799e2177407: Pull complete\n",
      "56d35ebee226: Pull complete\n",
      "f23d5847df7e: Pull complete\n",
      "85729b3aa914: Pull complete\n",
      "27594cd25c9b: Pull complete\n",
      "420dbd17143e: Pull complete\n",
      "71797a45a0de: Pull complete\n",
      "b073ad8b8421: Pull complete\n",
      "4b7516634a4b: Pull complete\n",
      "434af55afd20: Pull complete\n",
      "85d42009e725: Pull complete\n",
      "6d895d7b587a: Pull complete\n",
      "9ff76d709282: Pull complete\n",
      "4160ec915caf: Pull complete\n",
      "eb84f1e37919: Pull complete\n",
      "a616daa88ca5: Pull complete\n",
      "99b8f7435830: Pull complete\n",
      "1e2f495eab09: Pull complete\n",
      "d880b09bf9ec: Pull complete\n",
      "403fe241a00b: Pull complete\n",
      "ca533ed5e802: Pull complete\n",
      "9d118b4c5fa6: Pull complete\n",
      "388915f48178: Pull complete\n",
      "ddeefb06ab95: Pull complete\n",
      "62d0755e4559: Pull complete\n",
      "58a229d727c0: Pull complete\n",
      "c4606a99c9de: Pull complete\n",
      "Digest: sha256:1c90d7c7df1d78147013ae8d0377b1496b211391d740b88da6d9892946c30fb1\n",
      "Status: Downloaded newer image for gcr.io/tfx-oss-public/tfx:1.4.0\n",
      " ---> 8badc9bc28b6\n",
      "Step 2/4 : RUN pip install -U pip\n",
      " ---> Running in d6298c66392e\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (21.3.1)\n",
      "Collecting pip\n",
      "  Downloading pip-22.0.4-py3-none-any.whl (2.1 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 21.3.1\n",
      "    Uninstalling pip-21.3.1:\n",
      "      Successfully uninstalled pip-21.3.1\n",
      "Successfully installed pip-22.0.4\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container d6298c66392e\n",
      " ---> 36f74a73ff78\n",
      "Step 3/4 : RUN pip install google-cloud-aiplatform==1.7.1 kfp==1.8.1\n",
      " ---> Running in 593ae93f61cf\n",
      "Collecting google-cloud-aiplatform==1.7.1\n",
      "  Downloading google_cloud_aiplatform-1.7.1-py2.py3-none-any.whl (1.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 32.4 MB/s eta 0:00:00\n",
      "Collecting kfp==1.8.1\n",
      "  Downloading kfp-1.8.1.tar.gz (248 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 248.5/248.5 KB 30.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: proto-plus>=1.10.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform==1.7.1) (1.19.7)\n",
      "Requirement already satisfied: google-cloud-bigquery<3.0.0dev,>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform==1.7.1) (2.30.1)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform==1.7.1) (20.9)\n",
      "Requirement already satisfied: google-api-core[grpc]<3.0.0dev,>=1.26.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform==1.7.1) (1.31.4)\n",
      "Requirement already satisfied: google-cloud-storage<2.0.0dev,>=1.32.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform==1.7.1) (1.42.3)\n",
      "Collecting absl-py<=0.11,>=0.9\n",
      "  Downloading absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 127.8/127.8 KB 18.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: PyYAML<6,>=5.3 in /opt/conda/lib/python3.7/site-packages (from kfp==1.8.1) (5.4.1)\n",
      "Requirement already satisfied: kubernetes<19,>=8.0.0 in /opt/conda/lib/python3.7/site-packages (from kfp==1.8.1) (12.0.1)\n",
      "Requirement already satisfied: google-api-python-client<2,>=1.7.8 in /opt/conda/lib/python3.7/site-packages (from kfp==1.8.1) (1.12.8)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.1 in /opt/conda/lib/python3.7/site-packages (from kfp==1.8.1) (1.35.0)\n",
      "Collecting requests-toolbelt<1,>=0.8.0\n",
      "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.3/54.3 KB 8.2 MB/s eta 0:00:00\n",
      "Collecting cloudpickle<2,>=1.3.0\n",
      "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
      "Collecting kfp-server-api<2.0.0,>=1.1.2\n",
      "  Downloading kfp-server-api-1.8.1.tar.gz (54 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 KB 8.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting jsonschema<4,>=3.0.1\n",
      "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.3/56.3 KB 408.3 kB/s eta 0:00:00\n",
      "Collecting tabulate<1,>=0.8.6\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: click<8,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from kfp==1.8.1) (7.1.2)\n",
      "Collecting Deprecated<2,>=1.2.7\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting strip-hints<1,>=0.1.8\n",
      "  Downloading strip-hints-0.1.10.tar.gz (29 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting docstring-parser<1,>=0.7.3\n",
      "  Downloading docstring_parser-0.13.tar.gz (23 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: kfp-pipeline-spec<0.2.0,>=0.1.10 in /opt/conda/lib/python3.7/site-packages (from kfp==1.8.1) (0.1.13)\n",
      "Collecting fire<1,>=0.3.1\n",
      "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 87.7/87.7 KB 12.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: protobuf<4,>=3.13.0 in /opt/conda/lib/python3.7/site-packages (from kfp==1.8.1) (3.19.1)\n",
      "Requirement already satisfied: pydantic<2,>=1.8.2 in /opt/conda/lib/python3.7/site-packages (from kfp==1.8.1) (1.8.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py<=0.11,>=0.9->kfp==1.8.1) (1.15.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.7/site-packages (from Deprecated<2,>=1.2.7->kfp==1.8.1) (1.12.1)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.7/site-packages (from fire<1,>=0.3.1->kfp==1.8.1) (1.1.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.7.1) (2.25.1)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.7.1) (58.5.3)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.7.1) (2021.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.7.1) (1.53.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.29.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.7.1) (1.41.1)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp==1.8.1) (0.19.1)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp==1.8.1) (3.0.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp==1.8.1) (0.1.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp==1.8.1) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp==1.8.1) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp==1.8.1) (0.2.7)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.7.1) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.7.1) (2.8.2)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.7.1) (1.7.2)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp==1.8.1) (20.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp==1.8.1) (4.8.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp==1.8.1) (0.18.0)\n",
      "Requirement already satisfied: urllib3>=1.15 in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp==1.8.1) (1.26.7)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp==1.8.1) (2021.10.8)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.7/site-packages (from kubernetes<19,>=8.0.0->kfp==1.8.1) (1.3.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from kubernetes<19,>=8.0.0->kfp==1.8.1) (0.57.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=14.3->google-cloud-aiplatform==1.7.1) (2.4.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from pydantic<2,>=1.8.2->kfp==1.8.1) (3.7.4.3)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from strip-hints<1,>=0.1.8->kfp==1.8.1) (0.37.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.7.1) (1.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.1->kfp==1.8.1) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.7.1) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.7.1) (4.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->jsonschema<4,>=3.0.1->kfp==1.8.1) (3.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib->kubernetes<19,>=8.0.0->kfp==1.8.1) (3.1.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.7.1) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.7.1) (2.20)\n",
      "Building wheels for collected packages: kfp, docstring-parser, fire, kfp-server-api, strip-hints\n",
      "  Building wheel for kfp (setup.py): started\n",
      "  Building wheel for kfp (setup.py): finished with status 'done'\n",
      "  Created wheel for kfp: filename=kfp-1.8.1-py3-none-any.whl size=345340 sha256=7e370201caee08a9a86e05f599e19df1c7054f88c4f9910841702e3ce1b06c5d\n",
      "  Stored in directory: /root/.cache/pip/wheels/02/dd/71/45fa445fd9ea0c60ab0bd00b31760b1102ef2999f8002ee892\n",
      "  Building wheel for docstring-parser (pyproject.toml): started\n",
      "  Building wheel for docstring-parser (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for docstring-parser: filename=docstring_parser-0.13-py3-none-any.whl size=31866 sha256=83fe1be752622d5febd7446414a2850bcab22dba4498a072349e2338e6f73e45\n",
      "  Stored in directory: /root/.cache/pip/wheels/bd/88/3c/d1aa049309f7945178cac9fbe6561a86424f432da57c18ca0f\n",
      "  Building wheel for fire (setup.py): started\n",
      "  Building wheel for fire (setup.py): finished with status 'done'\n",
      "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115943 sha256=e3376074325e095eb464403a6eb874571b02dc28078d5cd67514571aa1c67787\n",
      "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
      "  Building wheel for kfp-server-api (setup.py): started\n",
      "  Building wheel for kfp-server-api (setup.py): finished with status 'done'\n",
      "  Created wheel for kfp-server-api: filename=kfp_server_api-1.8.1-py3-none-any.whl size=95548 sha256=1965355045e0f5e93d707d1b31c1f528e7f70a86e0b1c8bcafda692b4a866e84\n",
      "  Stored in directory: /root/.cache/pip/wheels/f5/4e/2e/6795bd3ed456a43652e7de100aca275ec179c9a8dfbcc65626\n",
      "  Building wheel for strip-hints (setup.py): started\n",
      "  Building wheel for strip-hints (setup.py): finished with status 'done'\n",
      "  Created wheel for strip-hints: filename=strip_hints-0.1.10-py2.py3-none-any.whl size=22302 sha256=2c394fcfd3b07eeb2942f954667214459132dd9d7ba5a175b50fdddbc76a2edb\n",
      "  Stored in directory: /root/.cache/pip/wheels/5e/14/c3/6e44e9b2545f2d570b03f5b6d38c00b7534aa8abb376978363\n",
      "Successfully built kfp docstring-parser fire kfp-server-api strip-hints\n",
      "Installing collected packages: tabulate, strip-hints, fire, docstring-parser, Deprecated, cloudpickle, absl-py, requests-toolbelt, kfp-server-api, jsonschema, kfp, google-cloud-aiplatform\n",
      "  Attempting uninstall: cloudpickle\n",
      "    Found existing installation: cloudpickle 2.0.0\n",
      "    Uninstalling cloudpickle-2.0.0:\n",
      "      Successfully uninstalled cloudpickle-2.0.0\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 0.12.0\n",
      "    Uninstalling absl-py-0.12.0:\n",
      "      Successfully uninstalled absl-py-0.12.0\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 4.1.2\n",
      "    Uninstalling jsonschema-4.1.2:\n",
      "      Successfully uninstalled jsonschema-4.1.2\n",
      "  Attempting uninstall: google-cloud-aiplatform\n",
      "    Found existing installation: google-cloud-aiplatform 1.6.2\n",
      "    Uninstalling google-cloud-aiplatform-1.6.2:\n",
      "      Successfully uninstalled google-cloud-aiplatform-1.6.2\n",
      "\u001b[91mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-io 0.18.0 requires tensorflow-io-gcs-filesystem==0.18.0, which is not installed.\n",
      "explainable-ai-sdk 1.3.2 requires xai-image-widget, which is not installed.\n",
      "tensorflow-io 0.18.0 requires tensorflow<2.6.0,>=2.5.0, but you have tensorflow 2.6.2 which is incompatible.\n",
      "\u001b[0mSuccessfully installed Deprecated-1.2.13 absl-py-0.11.0 cloudpickle-1.6.0 docstring-parser-0.13 fire-0.4.0 google-cloud-aiplatform-1.7.1 jsonschema-3.2.0 kfp-1.8.1 kfp-server-api-1.8.1 requests-toolbelt-0.9.1 strip-hints-0.1.10 tabulate-0.8.9\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 593ae93f61cf\n",
      " ---> dbdb9a6870b3\n",
      "Step 4/4 : COPY . ./\n",
      " ---> 1ed14dd50977\n",
      "Successfully built 1ed14dd50977\n",
      "Successfully tagged gcr.io/qwiklabs-gcp-01-9a9d18213c32/tfxcovertype:latest\n",
      "PUSH\n",
      "Pushing gcr.io/qwiklabs-gcp-01-9a9d18213c32/tfxcovertype\n",
      "The push refers to repository [gcr.io/qwiklabs-gcp-01-9a9d18213c32/tfxcovertype]\n",
      "d3f52853a2f7: Preparing\n",
      "e5536e4c5766: Preparing\n",
      "ce6f9cc47ade: Preparing\n",
      "47eadc53848d: Preparing\n",
      "360afeadb83c: Preparing\n",
      "610c8c70c225: Preparing\n",
      "11aaa1ad9bbe: Preparing\n",
      "c1540b4fd089: Preparing\n",
      "5be20e773bf8: Preparing\n",
      "f0aed3b553c7: Preparing\n",
      "e55c134eccb1: Preparing\n",
      "b3e660ff020a: Preparing\n",
      "1795fd5db4de: Preparing\n",
      "dad41956ce77: Preparing\n",
      "ab61683fbd20: Preparing\n",
      "117941aa2d3f: Preparing\n",
      "3a4c764c9a45: Preparing\n",
      "34db85e87fb0: Preparing\n",
      "782857218c62: Preparing\n",
      "195f2f019955: Preparing\n",
      "9546e4c87db8: Preparing\n",
      "78613865172b: Preparing\n",
      "97676aba1403: Preparing\n",
      "0fb4d6eba0b6: Preparing\n",
      "e8b9f9e4195c: Preparing\n",
      "eb1f25078652: Preparing\n",
      "b7ce5de9980f: Preparing\n",
      "0796fbb63752: Preparing\n",
      "1233ef617acb: Preparing\n",
      "390ace10d575: Preparing\n",
      "c1b078f0e002: Preparing\n",
      "70720fcb790d: Preparing\n",
      "e05247f7d2f8: Preparing\n",
      "ab7c37becce8: Preparing\n",
      "5ccc1cf20429: Preparing\n",
      "b2d48dbbbef2: Preparing\n",
      "260b0b2ff58a: Preparing\n",
      "6babb56be259: Preparing\n",
      "610c8c70c225: Waiting\n",
      "11aaa1ad9bbe: Waiting\n",
      "78613865172b: Waiting\n",
      "97676aba1403: Waiting\n",
      "0fb4d6eba0b6: Waiting\n",
      "c1540b4fd089: Waiting\n",
      "5be20e773bf8: Waiting\n",
      "f0aed3b553c7: Waiting\n",
      "e55c134eccb1: Waiting\n",
      "b3e660ff020a: Waiting\n",
      "e8b9f9e4195c: Waiting\n",
      "1795fd5db4de: Waiting\n",
      "eb1f25078652: Waiting\n",
      "b7ce5de9980f: Waiting\n",
      "0796fbb63752: Waiting\n",
      "1233ef617acb: Waiting\n",
      "390ace10d575: Waiting\n",
      "c1b078f0e002: Waiting\n",
      "70720fcb790d: Waiting\n",
      "e05247f7d2f8: Waiting\n",
      "ab7c37becce8: Waiting\n",
      "5ccc1cf20429: Waiting\n",
      "b2d48dbbbef2: Waiting\n",
      "260b0b2ff58a: Waiting\n",
      "6babb56be259: Waiting\n",
      "dad41956ce77: Waiting\n",
      "ab61683fbd20: Waiting\n",
      "117941aa2d3f: Waiting\n",
      "3a4c764c9a45: Waiting\n",
      "34db85e87fb0: Waiting\n",
      "782857218c62: Waiting\n",
      "195f2f019955: Waiting\n",
      "9546e4c87db8: Waiting\n",
      "360afeadb83c: Layer already exists\n",
      "47eadc53848d: Layer already exists\n",
      "11aaa1ad9bbe: Layer already exists\n",
      "610c8c70c225: Layer already exists\n",
      "5be20e773bf8: Layer already exists\n",
      "c1540b4fd089: Layer already exists\n",
      "f0aed3b553c7: Layer already exists\n",
      "e55c134eccb1: Layer already exists\n",
      "1795fd5db4de: Layer already exists\n",
      "b3e660ff020a: Layer already exists\n",
      "dad41956ce77: Layer already exists\n",
      "ab61683fbd20: Layer already exists\n",
      "117941aa2d3f: Layer already exists\n",
      "3a4c764c9a45: Layer already exists\n",
      "34db85e87fb0: Layer already exists\n",
      "d3f52853a2f7: Pushed\n",
      "782857218c62: Layer already exists\n",
      "195f2f019955: Layer already exists\n",
      "97676aba1403: Layer already exists\n",
      "78613865172b: Layer already exists\n",
      "9546e4c87db8: Layer already exists\n",
      "eb1f25078652: Layer already exists\n",
      "0fb4d6eba0b6: Layer already exists\n",
      "e8b9f9e4195c: Layer already exists\n",
      "1233ef617acb: Layer already exists\n",
      "b7ce5de9980f: Layer already exists\n",
      "0796fbb63752: Layer already exists\n",
      "70720fcb790d: Layer already exists\n",
      "c1b078f0e002: Layer already exists\n",
      "390ace10d575: Layer already exists\n",
      "ab7c37becce8: Layer already exists\n",
      "5ccc1cf20429: Layer already exists\n",
      "e05247f7d2f8: Layer already exists\n",
      "b2d48dbbbef2: Layer already exists\n",
      "6babb56be259: Layer already exists\n",
      "260b0b2ff58a: Layer already exists\n",
      "ce6f9cc47ade: Pushed\n",
      "e5536e4c5766: Pushed\n",
      "latest: digest: sha256:fd7624f890871a31762ca2a58e258490ecb8c1a8cbe725d0e5040935799fe244 size: 8311\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                                      IMAGES                                                      STATUS\n",
      "0930a72f-dd9a-496f-9a36-192540c67ca0  2022-04-01T16:50:47+00:00  9M44S     gs://qwiklabs-gcp-01-9a9d18213c32_cloudbuild/source/1648831847.092317-b1d29685a6e544ccb74429d40bf51f98.tgz  gcr.io/qwiklabs-gcp-01-9a9d18213c32/tfxcovertype (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit --timeout 15m --tag $TFX_IMAGE_URI ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile your pipeline code\n",
    "\n",
    "The following command will execute the `KubeflowV2DagRunner` that compiles the pipeline described in `pipeline.py` into a JSON representation consumable by Vertex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLI\n",
      "Compiling pipeline\n",
      "Pipeline tfxcovertype compiled successfully.\n"
     ]
    }
   ],
   "source": [
    "!tfx pipeline compile --engine vertex --pipeline_path runner.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: you should see a `{PIPELINE_NAME}.json` file appear in your current pipeline directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: deploy your pipeline on Vertex using the Vertex SDK\n",
    "\n",
    "Once you have the `{PIPELINE_NAME}.json` available, you can run the tfx pipeline on Vertex by launching a pipeline job using the `aiplatform` handle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/785019792420/locations/us-central1/pipelineJobs/tfxcovertype-20220401170951\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/785019792420/locations/us-central1/pipelineJobs/tfxcovertype-20220401170951')\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/tfxcovertype-20220401170951?project=785019792420\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/785019792420/locations/us-central1/pipelineJobs/tfxcovertype-20220401170951 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/785019792420/locations/us-central1/pipelineJobs/tfxcovertype-20220401170951 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/785019792420/locations/us-central1/pipelineJobs/tfxcovertype-20220401170951 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/785019792420/locations/us-central1/pipelineJobs/tfxcovertype-20220401170951 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/785019792420/locations/us-central1/pipelineJobs/tfxcovertype-20220401170951 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform as vertex_ai\n",
    "\n",
    "vertex_ai.init(project=PROJECT_ID,location=REGION)\n",
    "\n",
    "pipeline = vertex_ai.PipelineJob(\n",
    "    display_name=\"mypiplineTFX\",\n",
    "    template_path=PIPELINE_JSON,\n",
    "    enable_caching=False,\n",
    ")\n",
    "\n",
    "pipeline.run(service_account=\"qwiklabs-gcp-01-9a9d18213c32@qwiklabs-gcp-01-9a9d18213c32.iam.gserviceaccount.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you learned how to build and deploy a TFX pipeline with the TFX CLI and then update, build and deploy a new pipeline with automatic hyperparameter tuning. You practiced triggered continuous pipeline runs using the TFX CLI as well as the Kubeflow Pipelines UI.\n",
    "\n",
    "\n",
    "In the next lab, you will construct a Cloud Build CI/CD workflow that further automates the building and deployment of the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2021 Google Inc. All Rights Reserved.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "            http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "tf2-gpu.2-6.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m91"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
